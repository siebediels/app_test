{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## INTERACTIVE EXPLANATION TOOL"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4fb72125cc4fee999c688416f469f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"## INTERACTIVE EXPLANATION TOOL\"))\n",
    "intro_output = widgets.Output()\n",
    "display(intro_output)\n",
    "with intro_output:\n",
    "    clear_output(wait=True)\n",
    "    print(\"Initializing application...\")\n",
    "    \n",
    "def print_intro(text):\n",
    "    with intro_output:\n",
    "        print(text)\n",
    "        \n",
    "def intro_done():\n",
    "    intro_output.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DiCE\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers # helper functions\n",
    "\n",
    "# Tensorflow libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# supress deprecation warnings from TF\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "\n",
    "# Code deels gebaseerd op https://towardsdatascience.com/explainable-artificial-intelligence-part-3-hands-on-machine-learning-model-interpretation-e8ebe5afc608\n",
    "# en op de github repo's van LIME en SHAP.\n",
    "\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import xgboost\n",
    "import shap\n",
    "import time\n",
    "import os.path\n",
    "print_intro(\"Imported packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with intro_output:\n",
    "    shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = helpers.load_adult_income_dataset()\n",
    "print_intro(\"Dataset loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DiCE data object\n",
    "continuous_features=['age', 'hours_per_week']\n",
    "d = dice_ml.Data(dataframe=dataset, continuous_features=continuous_features, outcome_name='income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Creating dataset for LIME\n",
    "feature_names = dataset.columns.to_list()[:-1] # weggelaten: education_num, relationship, capital gain, capital loss, country\n",
    "labels = dataset.iloc[:,-1].to_numpy()\n",
    "data = dataset.iloc[:,:-1].to_numpy()\n",
    "class_names = np.array(['<=50K', '>50K'])\n",
    "categorical_features = [feature for feature in feature_names if feature not in continuous_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Encode categorical features\n",
    "categorical_features = [1,2,3,4,5,6]\n",
    "categorical_names = {}\n",
    "categorical_names_indexed_by_name = {}\n",
    "for feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(data[:, feature])\n",
    "    data[:, feature] = le.transform(data[:, feature])\n",
    "    categorical_names[feature] = le.classes_\n",
    "    categorical_names_indexed_by_name[feature_names[feature]] = le.classes_\n",
    "    \n",
    "def category_number_to_name(instance):\n",
    "    result = instance.astype('<U26')\n",
    "    for categorical_index in categorical_names.keys():\n",
    "        cat_label = int(instance[categorical_index])\n",
    "        result[categorical_index] = categorical_names[categorical_index][cat_label]\n",
    "    return result\n",
    "\n",
    "def category_name_to_number(instance):\n",
    "    result = np.copy(instance)\n",
    "    for categorical_index in categorical_names.keys():\n",
    "        number = np.where(categorical_names[categorical_index] == instance[categorical_index])\n",
    "        result[categorical_index] = number[0][0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Splitting train and test\n",
    "# using same random state for \"data\" (LIME) and \"dataset (DiCE)\"\n",
    "random_state = 17\n",
    "data = data.astype(float)\n",
    "np.random.seed(1)\n",
    "X_train_lime, X_test_lime, y_train_lime, y_test_lime = train_test_split(data, labels, random_state = random_state, \n",
    "                                                                        test_size=0.2)\n",
    "print_intro(\"Dataset preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeding random numbers for reproducability\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to load model, if not exists: train model\n",
    "model_name = \"keras_ann_v1\"\n",
    "model_path = \"../models/\"+model_name+\".h5\"\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "if (os.path.isfile(model_path)):\n",
    "    ann_model = tf.keras.models.load_model(model_path)\n",
    "    print_intro(\"Model loaded from disk\")\n",
    "    \n",
    "else:\n",
    "    print_intro(\"Training model\")\n",
    "\n",
    "    train, test = train_test_split(d.normalize_data(d.one_hot_encoded_data), random_state=random_state, test_size=0.2)\n",
    "    X_train = train.loc[:, train.columns != 'income']\n",
    "    y_train = train.loc[:, train.columns == 'income']\n",
    "\n",
    "    X_test = test.loc[:, test.columns != 'income']\n",
    "    y_test = test.loc[:, test.columns == 'income']\n",
    "\n",
    "    ann_model = keras.Sequential()\n",
    "    ann_model.add(keras.layers.Dense(20, input_shape=(X_train.shape[1],), kernel_regularizer=keras.regularizers.l1(0.001), activation=tf.nn.relu))\n",
    "    ann_model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "    ann_model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.01), metrics=['accuracy'])\n",
    "    ann_model.fit(X_train, y_train, validation_split=0.20, epochs=100, verbose=1, class_weight={0:1,1:2})\n",
    "    print(\"accuracy: \"+str(ann_model.history.history['acc'][-1]))\n",
    "    # the training will take some time for 100 epochs.\n",
    "    # you can wait or set verbose=1 to see the progress of training.\n",
    "    \n",
    "    # save model\n",
    "    ann_model.save(\"../models/\"+model_name+\".h5\")\n",
    "    print_intro(\"Model saved to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# DEPRECATED (OLD METHOD)\n",
    "def instance_to_dictionary(instance):\n",
    "    result = {}\n",
    "    for i in range(0,len(instance)):\n",
    "        feature = d.feature_names[i]\n",
    "        if feature in d.continuous_feature_names:\n",
    "            result[feature] = int(float(instance[i]))\n",
    "        else:\n",
    "            result[feature] = instance[i]\n",
    "    return result\n",
    "\n",
    "# numerieke lime categorien -> originele categorische namen --> dictionary --> one-hot-encode + normalisatie --> prediction_probability\n",
    "def predict_fn_lime(instances):\n",
    "    result = []\n",
    "    for instance in instances:\n",
    "        instance_categorical = category_number_to_name(instance)\n",
    "        instance_dict = instance_to_dictionary(instance_categorical)\n",
    "        \n",
    "        instance_transformed = d.prepare_query_instance(instance_dict, True)\n",
    "        \n",
    "        instance_prediction = ann_model.predict(instance_transformed)\n",
    "        result.append([1-instance_prediction[0][0], instance_prediction[0][0]])\n",
    "        \n",
    "    return np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "\n",
    "def inverse_categories(instances):\n",
    "    result = instances.astype('<U26')\n",
    "    for categorical_index in categorical_names.keys():\n",
    "        cat_labels = instances[:,categorical_index]\n",
    "        result[:,categorical_index] = [categorical_names[categorical_index][int(cat_label)] for cat_label in cat_labels]\n",
    "    return result\n",
    "\n",
    "def lime_instances_to_dice_ml(instances):\n",
    "    base_frame = d.prepare_df_for_encoding()\n",
    "    \n",
    "    instances_categorical = inverse_categories(instances)\n",
    "\n",
    "    instance_dataframe = pd.DataFrame(instances_categorical,columns=feature_names)\n",
    "    instance_dataframe['age'] = pd.to_numeric(instance_dataframe['age'])\n",
    "    instance_dataframe['hours_per_week'] = pd.to_numeric(instance_dataframe['hours_per_week'])\n",
    "\n",
    "    \"\"\"Prepares user defined test input for DiCE.\"\"\"\n",
    "    temp = base_frame.append(instance_dataframe, ignore_index=True, sort=False)\n",
    "    temp = d.one_hot_encode_data(temp)\n",
    "    temp = d.normalize_data(temp)\n",
    "    final = temp.tail(instance_dataframe.shape[0]).reset_index(drop=True)\n",
    "    return final\n",
    "\n",
    "def lime_instance_to_dict(instance):\n",
    "    temp = dict(zip(feature_names,category_number_to_name(instance)))\n",
    "    temp['age'] = int(float(temp['age']))\n",
    "    temp['hours_per_week'] = int(float(temp['hours_per_week']))\n",
    "    return temp\n",
    "\n",
    "def dict_to_lime_instance(instance_dict):\n",
    "    instance_array = np.array(list(instance_dict.values()))\n",
    "    return category_name_to_number(instance_array).astype('float')\n",
    "\n",
    "def pd_to_dataframe(instance):\n",
    "    return pd.DataFrame(instance.reshape(-1, len(instance)),columns=feature_names)\n",
    "\n",
    "def predict_fn_lime_superquick(instances):\n",
    "    converted_to_dice = lime_instances_to_dice_ml(instances)\n",
    "    predictions = ann_model.predict(converted_to_dice)\n",
    "    return np.append(1-predictions, predictions, axis=1)\n",
    "\n",
    "def predict_fn_shap_superquick(instances):\n",
    "    converted_to_dice = lime_instances_to_dice_ml(instances)\n",
    "    predictions = ann_model.predict(converted_to_dice)\n",
    "    return np.array([pred[0] for pred in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the trained ML model to DiCE's model object\n",
    "backend = 'TF'+tf.__version__[0] # TF1\n",
    "m = dice_ml.Model(model=ann_model, backend=backend) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate DiCE\n",
    "exp = dice_ml.Dice(d, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "explainer_lime = LimeTabularExplainer(X_train_lime ,feature_names = feature_names,class_names=class_names,\n",
    "                                                   categorical_features=categorical_features, \n",
    "                                                   categorical_names=categorical_names, kernel_width=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# %%capture dient om een vervelende warning te onderdrukken (doet alle output van deze cell weg)\n",
    "############################## SHAP\n",
    "\n",
    "# Median is simpelweg de mediaan van elke feature in de training set. In deze setting wordt telkens de mediaan van een feature als baseline gebruikt (ze krijgt deze waarde bij het \"wegdoen\")\n",
    "# INFO: De base value op de figuur is de uitkomst die de blackbox geeft voor de mediaan als input.\n",
    "med = np.median(X_train_lime, axis=0).reshape((1,X_train_lime.shape[1]))\n",
    "\n",
    "explainer_shap = shap.KernelExplainer(predict_fn_shap_superquick, med)\n",
    "\n",
    "def plot_explanation_for_shap(instance):\n",
    "    shap_values_for_instance = explainer_shap.shap_values(instance, nsamples=1000)\n",
    "    return shap.force_plot(explainer_shap.expected_value, shap_values_for_instance, category_number_to_name(instance), feature_names = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_prediction(instance):\n",
    "    pred_prob = predict_fn_shap_superquick(np.array([instance]))[0]\n",
    "    if pred_prob > 0.5:\n",
    "        return \"Model prediction: >50K (probability: \"+str(round(pred_prob,2))+\")\"\n",
    "    else:\n",
    "        return \"Model prediction: <50K (probability: \"+str(round(1-pred_prob,2))+\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_intro(\"Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_adjusters(instance):\n",
    "    feature_adjusters = {}\n",
    "    style = {'description_width': '100px'}\n",
    "    for feature in feature_names:\n",
    "        if feature in continuous_features:\n",
    "            feature_range = d.get_features_range()[feature]\n",
    "            adjuster = widgets.IntSlider(value=int(float(instance[feature])), min=feature_range[0], max=feature_range[1], step=1, description=feature, disabled=False, \n",
    "                                         continuous_update=False, orientation='horizontal', readout=True, readout_format='d', style=style, layout=Layout(width='425px'))\n",
    "        else:\n",
    "            subcategories = categorical_names_indexed_by_name[feature]\n",
    "            adjuster = widgets.Dropdown(options=subcategories, value=str(instance[feature][0]), description=feature, disabled=False, style=style, layout=Layout(width='400px'))\n",
    "            \n",
    "        feature_adjusters[feature] = adjuster\n",
    "    return feature_adjusters\n",
    "\n",
    "def link_adjusters_to_callback(adjusters, callback):\n",
    "    for adjuster in adjusters.values():\n",
    "        adjuster.observe(callback, names='value')\n",
    "\n",
    "def get_adjusters_values(adjusters):\n",
    "    return {item[0]:item[1].value for item in adjusters.items()}\n",
    "\n",
    "def get_dataframe_from_adjusters(adjusters):\n",
    "    values = list(get_adjusters_values(adjusters).values())\n",
    "    return pd.DataFrame([values],columns=feature_names)\n",
    "\n",
    "def set_adjuster_values(adjusters, values):\n",
    "    for feature in feature_names:\n",
    "        if feature in continuous_features:\n",
    "            adjusters[feature].value = int(float(values[feature]))\n",
    "        else:\n",
    "            adjusters[feature].value = str(values[feature][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_toggles(instance):\n",
    "    feature_toggles = {}\n",
    "    style = {'description_width': '100px'}\n",
    "    for feature in feature_names: #info, warning, success, danger\n",
    "        toggle = widgets.ToggleButton(value=False, description='unlocked', disabled=False, button_style='info',\n",
    "                                    tooltip='Click to lock this feature', icon='unlock') # (FontAwesome names without the `fa-` prefix)\n",
    "        toggle.observe(on_toggle_click, 'value')\n",
    "        feature_toggles[feature] = toggle\n",
    "    return feature_toggles\n",
    "\n",
    "def get_toggle_button_name(toggle):\n",
    "    for feature in toggles:\n",
    "        if toggles[feature] == toggle:\n",
    "            return feature\n",
    "\n",
    "def on_toggle_click(d):\n",
    "    t = d['owner']\n",
    "    if t.value == True:\n",
    "        t.description = \"locked\"\n",
    "        t.icon = \"lock\"\n",
    "        t.tooltip = \"Click to unlock this feature\"\n",
    "        t.button_style = \"danger\"\n",
    "    else:\n",
    "        t.description = \"unlocked\"\n",
    "        t.icon = \"unlock\"\n",
    "        t.tooltip = \"Click to lock this feature\"\n",
    "        t.button_style = \"info\"\n",
    "    feature_name = get_toggle_button_name(t)\n",
    "    if feature_name in continuous_features:\n",
    "        hide_slider(feature_name, t.value)\n",
    "        \n",
    "def initialize_sliders(instance):\n",
    "    feature_sliders = {}\n",
    "    for feature in continuous_features:\n",
    "        slider_range = d.get_features_range()[feature]\n",
    "        slider = widgets.IntRangeSlider(value=slider_range, min=slider_range[0], max=slider_range[1], step=1, description=feature, disabled=False, continuous_update=False, \n",
    "                                orientation='horizontal', readout=True, readout_format='d', style = {'description_width': '95px'},layout=Layout(width='330px'))\n",
    "        feature_sliders[feature] = slider\n",
    "    return feature_sliders\n",
    "\n",
    "def hide_slider(feature_name, hide):\n",
    "    slider = sliders[feature_name]\n",
    "    if hide:\n",
    "        slider.layout.visibility = 'hidden'\n",
    "    else:\n",
    "        slider.layout.visibility = 'visible'\n",
    "    \n",
    "def get_toggle_label_box(toggles):\n",
    "    vertical_list = []\n",
    "    for feature in feature_names:\n",
    "        label_layout = Layout(width='100px')\n",
    "        label = widgets.Label(value=feature, layout=label_layout)\n",
    "        hbox = widgets.HBox([label,toggles[feature]])\n",
    "        vertical_list.append(hbox)\n",
    "    return widgets.VBox(vertical_list)\n",
    "\n",
    "def get_features_to_vary():\n",
    "    result = []\n",
    "    for feature in feature_names:\n",
    "        if toggles[feature].value == False:\n",
    "            result.append(feature)\n",
    "    return result\n",
    "            \n",
    "def get_feature_ranges():\n",
    "    new_ranges = {}\n",
    "    for feature in continuous_features:\n",
    "        new_ranges[feature] = sliders[feature].value\n",
    "    return new_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87528a8ed9c40e8bf0a3e811ae8115f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=42, continuous_update=False, description='age', layout=Layout(width='425px'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85af58e0d611418a83de8b0026504f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='warning', description='Reset', style=ButtonStyle()), Button(button_style='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0475190c39d46baa1ce0654def75b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee09409ecd54b60b21da96418e4b556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630cce78a3c9440db334fe5fd5d10ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = pd_to_dataframe(category_number_to_name(X_test_lime[2,:]))\n",
    "adjusters = initialize_adjusters(test)\n",
    "output_prediction = widgets.Output()\n",
    "output_explanation = widgets.Output()\n",
    "output_counterfactuals = widgets.Output()\n",
    "output_constraints = widgets.Output()\n",
    "output_dice = widgets.Output()\n",
    "output_bin = widgets.Output()\n",
    "\n",
    "def adjuster_changed(change):\n",
    "    with output_explanation:\n",
    "        clear_output(wait=True)\n",
    "        print(\"\")\n",
    "    with output_prediction:\n",
    "        clear_output(wait=True)\n",
    "        print(\"\")\n",
    "    with output_counterfactuals:\n",
    "        clear_output(wait=True)\n",
    "        print(\"\")\n",
    "    \n",
    "link_adjusters_to_callback(adjusters, adjuster_changed)\n",
    "\n",
    "def reset_adjusters(b):\n",
    "    set_adjuster_values(adjusters,test)\n",
    "    with output_counterfactuals:\n",
    "        clear_output()\n",
    "    with output_explanation:\n",
    "        clear_output()\n",
    "    with output_prediction:\n",
    "        clear_output(wait=True)\n",
    "        print(\"Reset to default\")\n",
    "\n",
    "button_reset = widgets.Button(description=\"Reset\", button_style = 'warning')\n",
    "button_reset.on_click(reset_adjusters)\n",
    "\n",
    "def on_button_predict_clicked(b):\n",
    "    instance_dataframe = get_dataframe_from_adjusters(adjusters)\n",
    "    instance_lime = category_name_to_number(instance_dataframe.to_numpy()[0]).astype('float')\n",
    "    button_counterfactuals.layout.visibility = 'visible'\n",
    "    \n",
    "    with output_counterfactuals:\n",
    "        clear_output()\n",
    "    \n",
    "    with output_explanation:\n",
    "        clear_output(wait=True)\n",
    "        print(\"\")\n",
    "        \n",
    "    with output_prediction:\n",
    "        clear_output(wait=True)\n",
    "        display(Markdown(\"#### <br>__\"+print_model_prediction(instance_lime)+\"__<br>\"))\n",
    "        #display(instance_dataframe)\n",
    "        display(widgets.HBox([explanation_type,button_explain, button_counterfactuals]))\n",
    "\n",
    "button_predict = widgets.Button(description=\"Predict outcome\", button_style = 'primary')\n",
    "button_predict.on_click(on_button_predict_clicked)\n",
    "\n",
    "explanation_type = widgets.Dropdown(options=['LIME', 'SHAP', 'LIME+SHAP'], value='LIME', description='', disabled=False, layout=Layout(width='143px'))\n",
    "\n",
    "def on_button_explain_clicked(b):\n",
    "    instance_dataframe = get_dataframe_from_adjusters(adjusters)\n",
    "    instance_lime = category_name_to_number(instance_dataframe.to_numpy()[0]).astype('float')\n",
    "    with output_explanation:\n",
    "            clear_output(wait=True)\n",
    "    if (explanation_type.value == \"LIME\" or explanation_type.value == \"LIME+SHAP\"):\n",
    "        with output_explanation:\n",
    "            display(Markdown(\"#### __LIME explanation__\"))\n",
    "            explainer_lime.explain_instance(instance_lime, predict_fn_lime_superquick, num_features=5).show_in_notebook(show_all=False, predict_proba=False)\n",
    "        \n",
    "    if (explanation_type.value == \"SHAP\" or explanation_type.value == \"LIME+SHAP\"):\n",
    "        with output_explanation:\n",
    "            display(Markdown(\"#### __SHAP explanation__\"))\n",
    "        shap_values_for_instance = explainer_shap.shap_values(instance_lime, nsamples=1000)\n",
    "        with output_explanation:\n",
    "            display(shap.force_plot(explainer_shap.expected_value, shap_values_for_instance, category_number_to_name(instance_lime), feature_names = feature_names))\n",
    "\n",
    "button_explain = widgets.Button(description=\"Explain outcome\", button_style = 'primary')\n",
    "button_explain.on_click(on_button_explain_clicked)\n",
    "\n",
    "def on_button_counterfactuals_clicked(b):\n",
    "    button_counterfactuals.layout.visibility = 'hidden'\n",
    "    \n",
    "    with output_counterfactuals:\n",
    "        clear_output(wait=True)\n",
    "        display(widgets.HBox([output_constraints,output_dice]))\n",
    "    load_constraints()\n",
    "    load_counterfactuals_dice()\n",
    "    \n",
    "      \n",
    "button_counterfactuals = widgets.Button(description=\"Find counterfactuals\", button_style = 'primary')\n",
    "button_counterfactuals.on_click(on_button_counterfactuals_clicked)\n",
    "\n",
    "def on_button_search_clicked(b):\n",
    "    instance_dataframe = get_dataframe_from_adjusters(adjusters)\n",
    "    instance_lime = category_name_to_number(instance_dataframe.to_numpy()[0]).astype('float')\n",
    "    load_counterfactuals_dice()\n",
    "        \n",
    "button_search = widgets.Button(description=\"Search within constraints\", button_style = 'primary', layout=Layout(width='320px'))\n",
    "button_search.on_click(on_button_search_clicked)\n",
    "\n",
    "def load_constraints():\n",
    "    with output_constraints:\n",
    "        clear_output(wait=True)\n",
    "        display(Markdown(\"#### __Counterfactual constraints__\"))\n",
    "        display(final_box)\n",
    "\n",
    "def load_counterfactuals_dice():\n",
    "    instance_dataframe = get_dataframe_from_adjusters(adjusters)\n",
    "    instance_lime = category_name_to_number(instance_dataframe.to_numpy()[0]).astype('float')\n",
    "    with output_dice:\n",
    "        clear_output()\n",
    "        display(Markdown(\"#### __Counterfactual outcomes__\"))\n",
    "        print(\"Searching counterfactuals..\")\n",
    "        clear_output(wait=True)\n",
    "    d.permitted_range = get_feature_ranges()\n",
    "    exp = dice_ml.Dice(d, m)\n",
    "    with output_bin:\n",
    "        dice_exp = exp.generate_counterfactuals(lime_instance_to_dict(instance_lime), total_CFs=4, desired_class=\"opposite\", features_to_vary=get_features_to_vary())\n",
    "    with output_dice:\n",
    "        display(Markdown(\"#### __Counterfactual outcomes__\"))\n",
    "        dice_exp.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "toggles = initialize_toggles(test)\n",
    "sliders = initialize_sliders(test)\n",
    "toggle_box = get_toggle_label_box(toggles)\n",
    "final_list = [toggle_box]\n",
    "final_list.extend(list(sliders.values()))\n",
    "final_list.append(button_search)\n",
    "final_box = widgets.VBox(final_list)\n",
    "\n",
    "display(widgets.VBox(list(adjusters.values())))\n",
    "display(widgets.HBox([button_reset,button_predict]))\n",
    "display(output_prediction)\n",
    "display(output_explanation)\n",
    "display(output_counterfactuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis_kernel",
   "language": "python",
   "name": "thesis_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
