{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## EXPLANATION TOOL"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90b295102c0407384dd1a3622b36ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"## EXPLANATION TOOL\"))\n",
    "intro_output = widgets.Output()\n",
    "display(intro_output)\n",
    "with intro_output:\n",
    "    clear_output(wait=True)\n",
    "    print(\"Initializing application...\")\n",
    "    \n",
    "def print_intro(text):\n",
    "    with intro_output:\n",
    "        print(text)\n",
    "        \n",
    "def intro_done():\n",
    "    with intro_output:\n",
    "        clear_output(wait=True)\n",
    "        print(\"Build succesful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DiCE\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers # helper functions\n",
    "\n",
    "# Tensorflow libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# supress deprecation warnings from TF\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "\n",
    "# Code deels gebaseerd op https://towardsdatascience.com/explainable-artificial-intelligence-part-3-hands-on-machine-learning-model-interpretation-e8ebe5afc608\n",
    "# en op de github repo's van LIME en SHAP.\n",
    "\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import xgboost\n",
    "import shap\n",
    "import time\n",
    "import os.path\n",
    "with intro_output:\n",
    "    shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = helpers.load_adult_income_dataset()\n",
    "print_intro(\"Dataset loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DiCE data object\n",
    "continuous_features=['age', 'hours_per_week']\n",
    "d = dice_ml.Data(dataframe=dataset, continuous_features=continuous_features, outcome_name='income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Creating dataset for LIME\n",
    "feature_names = dataset.columns.to_list()[:-1] # weggelaten: education_num, relationship, capital gain, capital loss, country\n",
    "labels = dataset.iloc[:,-1].to_numpy()\n",
    "data = dataset.iloc[:,:-1].to_numpy()\n",
    "class_names = np.array(['<=50K', '>50K'])\n",
    "categorical_features = [feature for feature in feature_names if feature not in continuous_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Encode categorical features\n",
    "categorical_features = [1,2,3,4,5,6]\n",
    "categorical_names = {}\n",
    "categorical_names_indexed_by_name = {}\n",
    "for feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(data[:, feature])\n",
    "    data[:, feature] = le.transform(data[:, feature])\n",
    "    categorical_names[feature] = le.classes_\n",
    "    categorical_names_indexed_by_name[feature_names[feature]] = le.classes_\n",
    "    \n",
    "def category_number_to_name(instance):\n",
    "    result = instance.astype('<U26')\n",
    "    for categorical_index in categorical_names.keys():\n",
    "        cat_label = int(instance[categorical_index])\n",
    "        result[categorical_index] = categorical_names[categorical_index][cat_label]\n",
    "    return result\n",
    "\n",
    "def category_name_to_number(instance):\n",
    "    result = np.copy(instance)\n",
    "    for categorical_index in categorical_names.keys():\n",
    "        number = np.where(categorical_names[categorical_index] == instance[categorical_index])\n",
    "        result[categorical_index] = number[0][0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Splitting train and test\n",
    "# using same random state for \"data\" (LIME) and \"dataset (DiCE)\"\n",
    "random_state = 17\n",
    "data = data.astype(float)\n",
    "np.random.seed(1)\n",
    "X_train_lime, X_test_lime, y_train_lime, y_test_lime = train_test_split(data, labels, random_state = random_state, \n",
    "                                                                        test_size=0.2)\n",
    "print_intro(\"Dataset preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeding random numbers for reproducability\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n"
     ]
    }
   ],
   "source": [
    "# try to load model, if not exists: train model\n",
    "model_name = \"keras_ann_v1\"\n",
    "model_path = \"../models/\"+model_name+\".h5\"\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "if (os.path.isfile(model_path)):\n",
    "    ann_model = tf.keras.models.load_model(model_path)\n",
    "    print_intro(\"Model loaded from disk\")\n",
    "    \n",
    "else:\n",
    "    print_intro(\"Training model\")\n",
    "\n",
    "    train, test = train_test_split(d.normalize_data(d.one_hot_encoded_data), random_state=random_state, test_size=0.2)\n",
    "    X_train = train.loc[:, train.columns != 'income']\n",
    "    y_train = train.loc[:, train.columns == 'income']\n",
    "\n",
    "    X_test = test.loc[:, test.columns != 'income']\n",
    "    y_test = test.loc[:, test.columns == 'income']\n",
    "\n",
    "    ann_model = keras.Sequential()\n",
    "    ann_model.add(keras.layers.Dense(20, input_shape=(X_train.shape[1],), kernel_regularizer=keras.regularizers.l1(0.001), activation=tf.nn.relu))\n",
    "    ann_model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "    ann_model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.01), metrics=['accuracy'])\n",
    "    ann_model.fit(X_train, y_train, validation_split=0.20, epochs=100, verbose=1, class_weight={0:1,1:2})\n",
    "    print(\"accuracy: \"+str(ann_model.history.history['acc'][-1]))\n",
    "    # the training will take some time for 100 epochs.\n",
    "    # you can wait or set verbose=1 to see the progress of training.\n",
    "    \n",
    "    # save model\n",
    "    ann_model.save(\"../models/\"+model_name+\".h5\")\n",
    "    print_intro(\"Model saved to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# DEPRECATED (OLD METHOD)\n",
    "def instance_to_dictionary(instance):\n",
    "    result = {}\n",
    "    for i in range(0,len(instance)):\n",
    "        feature = d.feature_names[i]\n",
    "        if feature in d.continuous_feature_names:\n",
    "            result[feature] = int(float(instance[i]))\n",
    "        else:\n",
    "            result[feature] = instance[i]\n",
    "    return result\n",
    "\n",
    "# numerieke lime categorien -> originele categorische namen --> dictionary --> one-hot-encode + normalisatie --> prediction_probability\n",
    "def predict_fn_lime(instances):\n",
    "    result = []\n",
    "    for instance in instances:\n",
    "        instance_categorical = category_number_to_name(instance)\n",
    "        instance_dict = instance_to_dictionary(instance_categorical)\n",
    "        \n",
    "        instance_transformed = d.prepare_query_instance(instance_dict, True)\n",
    "        \n",
    "        instance_prediction = ann_model.predict(instance_transformed)\n",
    "        result.append([1-instance_prediction[0][0], instance_prediction[0][0]])\n",
    "        \n",
    "    return np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "\n",
    "def inverse_categories(instances):\n",
    "    result = instances.astype('<U26')\n",
    "    for categorical_index in categorical_names.keys():\n",
    "        cat_labels = instances[:,categorical_index]\n",
    "        result[:,categorical_index] = [categorical_names[categorical_index][int(cat_label)] for cat_label in cat_labels]\n",
    "    return result\n",
    "\n",
    "def lime_instances_to_dice_ml(instances):\n",
    "    base_frame = d.prepare_df_for_encoding()\n",
    "    \n",
    "    instances_categorical = inverse_categories(instances)\n",
    "\n",
    "    instance_dataframe = pd.DataFrame(instances_categorical,columns=feature_names)\n",
    "    instance_dataframe['age'] = pd.to_numeric(instance_dataframe['age'])\n",
    "    instance_dataframe['hours_per_week'] = pd.to_numeric(instance_dataframe['hours_per_week'])\n",
    "\n",
    "    \"\"\"Prepares user defined test input for DiCE.\"\"\"\n",
    "    temp = base_frame.append(instance_dataframe, ignore_index=True, sort=False)\n",
    "    temp = d.one_hot_encode_data(temp)\n",
    "    temp = d.normalize_data(temp)\n",
    "    final = temp.tail(instance_dataframe.shape[0]).reset_index(drop=True)\n",
    "    return final\n",
    "\n",
    "def lime_instance_to_dict(instance):\n",
    "    temp = dict(zip(feature_names,category_number_to_name(instance)))\n",
    "    temp['age'] = int(float(temp['age']))\n",
    "    temp['hours_per_week'] = int(float(temp['hours_per_week']))\n",
    "    return temp\n",
    "\n",
    "def dict_to_lime_instance(instance_dict):\n",
    "    instance_array = np.array(list(instance_dict.values()))\n",
    "    return category_name_to_number(instance_array).astype('float')\n",
    "\n",
    "def pd_to_dataframe(instance):\n",
    "    return pd.DataFrame(instance.reshape(-1, len(instance)),columns=feature_names)\n",
    "\n",
    "def predict_fn_lime_superquick(instances):\n",
    "    converted_to_dice = lime_instances_to_dice_ml(instances)\n",
    "    predictions = ann_model.predict(converted_to_dice)\n",
    "    return np.append(1-predictions, predictions, axis=1)\n",
    "\n",
    "def predict_fn_shap_superquick(instances):\n",
    "    converted_to_dice = lime_instances_to_dice_ml(instances)\n",
    "    predictions = ann_model.predict(converted_to_dice)\n",
    "    return np.array([pred[0] for pred in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the trained ML model to DiCE's model object\n",
    "backend = 'TF'+tf.__version__[0] # TF1\n",
    "m = dice_ml.Model(model=ann_model, backend=backend) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate DiCE\n",
    "exp = dice_ml.Dice(d, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "explainer_lime = LimeTabularExplainer(X_train_lime ,feature_names = feature_names,class_names=class_names,\n",
    "                                                   categorical_features=categorical_features, \n",
    "                                                   categorical_names=categorical_names, kernel_width=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# %%capture dient om een vervelende warning te onderdrukken (doet alle output van deze cell weg)\n",
    "############################## SHAP\n",
    "\n",
    "# Median is simpelweg de mediaan van elke feature in de training set. In deze setting wordt telkens de mediaan van een feature als baseline gebruikt (ze krijgt deze waarde bij het \"wegdoen\")\n",
    "# INFO: De base value op de figuur is de uitkomst die de blackbox geeft voor de mediaan als input.\n",
    "med = np.median(X_train_lime, axis=0).reshape((1,X_train_lime.shape[1]))\n",
    "\n",
    "explainer_shap = shap.KernelExplainer(predict_fn_shap_superquick, med)\n",
    "\n",
    "def plot_explanation_for_shap(instance):\n",
    "    shap_values_for_instance = explainer_shap.shap_values(instance, nsamples=1000)\n",
    "    return shap.force_plot(explainer_shap.expected_value, shap_values_for_instance, category_number_to_name(instance), feature_names = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_prediction(instance):\n",
    "    pred_prob = predict_fn_shap_superquick(np.array([instance]))[0]\n",
    "    if pred_prob > 0.5:\n",
    "        return \"Model prediction: >50K (probability: \"+str(round(pred_prob,2))+\")\"\n",
    "    else:\n",
    "        return \"Model prediction: <50K (probability: \"+str(round(1-pred_prob,2))+\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_adjusters(instance):\n",
    "    feature_adjusters = {}\n",
    "    style = {'description_width': '100px'}\n",
    "    for feature in feature_names:\n",
    "        if feature in continuous_features:\n",
    "            feature_range = d.get_features_range()[feature]\n",
    "            adjuster = widgets.IntSlider(value=int(float(instance[feature])), min=feature_range[0], max=feature_range[1], step=1, description=feature, disabled=False, continuous_update=False, \n",
    "                                       orientation='horizontal', readout=True, readout_format='d', style=style, layout=Layout(width='425px'))\n",
    "        else:\n",
    "            subcategories = categorical_names_indexed_by_name[feature]\n",
    "            adjuster = widgets.Dropdown(options=subcategories, value=str(instance[feature][0]), description=feature, disabled=False, style=style, layout=Layout(width='400px'))\n",
    "            \n",
    "        feature_adjusters[feature] = adjuster\n",
    "    return feature_adjusters\n",
    "\n",
    "def get_adjusters_values(adjusters):\n",
    "    return {item[0]:item[1].value for item in adjusters.items()}\n",
    "\n",
    "def get_dataframe_from_adjusters(adjusters):\n",
    "    values = list(get_adjusters_values(adjusters).values())\n",
    "    return pd.DataFrame([values],columns=feature_names)\n",
    "\n",
    "def set_adjuster_values(adjusters, values):\n",
    "    for feature in feature_names:\n",
    "        if feature in continuous_features:\n",
    "            adjusters[feature].value = int(float(values[feature]))\n",
    "        else:\n",
    "            adjusters[feature].value = str(values[feature][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## EXPLANATION TOOL"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55264c3ff5a4d6997a3856015b45d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=54, continuous_update=False, description='age', layout=Layout(width='425px'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9478171312ef487c8b0654af1546b2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='warning', description='Reset', style=ButtonStyle()), Button(button_style='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03d092942bc4714981867a2b4e1c9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = pd_to_dataframe(category_number_to_name(X_test_lime[0,:]))\n",
    "adjusters = initialize_adjusters(test)\n",
    "output_explanation = widgets.Output()\n",
    "\n",
    "def reset_adjusters(b):\n",
    "    set_adjuster_values(adjusters,test)\n",
    "    with output_explanation:\n",
    "        clear_output(wait=True)\n",
    "        print(\"Reset to default\")\n",
    "\n",
    "button_reset = widgets.Button(description=\"Reset\", button_style = 'warning')\n",
    "button_reset.on_click(reset_adjusters)\n",
    "    \n",
    "\n",
    "def on_button_explain_clicked(b):\n",
    "    with output_explanation:\n",
    "        clear_output(wait=True)\n",
    "        instance_dataframe = get_dataframe_from_adjusters(adjusters)\n",
    "        instance_lime = category_name_to_number(instance_dataframe.to_numpy()[0]).astype('float')\n",
    "        \n",
    "        display(instance_dataframe)\n",
    "        display(Markdown(print_model_prediction(instance_lime)+\"<br><br>\"))\n",
    "        \n",
    "        display(Markdown(\"#### __LIME explanation__\"))\n",
    "        explainer_lime.explain_instance(instance_lime, predict_fn_lime_superquick, num_features=5).show_in_notebook(show_all=False)\n",
    "        \n",
    "        display(Markdown(\"#### __SHAP explanation__\"))\n",
    "        display(plot_explanation_for_shap(instance_lime))\n",
    "        \n",
    "        display(Markdown(\"#### __Counterfactual explanation__\"))\n",
    "        dice_exp = exp.generate_counterfactuals(lime_instance_to_dict(instance_lime), total_CFs=4, desired_class=\"opposite\")\n",
    "        dice_exp.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "button_explain = widgets.Button(description=\"Predict and Explain\", button_style = 'primary')\n",
    "button_explain.on_click(on_button_explain_clicked)\n",
    "\n",
    "display(widgets.VBox(list(adjusters.values())))\n",
    "display(widgets.HBox([button_reset, button_explain]))\n",
    "display(output_explanation)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis_kernel",
   "language": "python",
   "name": "thesis_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
